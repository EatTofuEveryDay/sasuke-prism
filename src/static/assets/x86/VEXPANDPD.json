{"title":"VEXPANDPD â€” Load Sparse Packed Double-Precision Floating-Point Values from Dense Memory","fields":[{"name":"Instruction Modes","value":"`VEXPANDPD xmm1 {k1}{z}, xmm2/m128`\n`VEXPANDPD ymm1 {k1}{z}, ymm2/m256`\n`VEXPANDPD zmm1 {k1}{z}, zmm2/m512`"},{"name":"Description","value":"Expand (load) up to 8/4/2, contiguous, double-precision floating-point values of the input vector in the source operand (the second operand) to sparse elements in the destination operand (the first operand) selected by the writemask k1."},{"name":"\u200b","value":"The destination operand is a ZMM/YMM/XMM register, the source operand can be a ZMM/YMM/XMM register or a 512/256/128-bit memory location."},{"name":"\u200b","value":"The input vector starts from the lowest element in the source operand. The writemask register k1 selects the destination elements (a partial vector or sparse elements if less than 8 elements) to be replaced by the ascending elements in the input vector. Destination elements not selected by the writemask k1 are either unmodified or zeroed, depending on EVEX.z."},{"name":"\u200b","value":"EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD."},{"name":"\u200b","value":"Note that the compressed displacement assumes a pre-scaling (N) corresponding to the size of one single element instead of the size of the full vector."},{"name":"C/C++ Intriniscs","value":"`VEXPANDPD __m512d _mm512_mask_expand_pd( __m512d s, __mmask8 k, __m512d a);\n`"},{"name":"\u200b","value":"`VEXPANDPD __m512d _mm512_maskz_expand_pd( __mmask8 k, __m512d a);\n`"},{"name":"\u200b","value":"`VEXPANDPD __m512d _mm512_mask_expandloadu_pd( __m512d s, __mmask8 k, void * a);\n`"},{"name":"\u200b","value":"`VEXPANDPD __m512d _mm512_maskz_expandloadu_pd( __mmask8 k, void * a);\n`"},{"name":"\u200b","value":"`VEXPANDPD __m256d _mm256_mask_expand_pd( __m256d s, __mmask8 k, __m256d a);\n`"},{"name":"\u200b","value":"`VEXPANDPD __m256d _mm256_maskz_expand_pd( __mmask8 k, __m256d a);\n`"},{"name":"\u200b","value":"`VEXPANDPD __m256d _mm256_mask_expandloadu_pd( __m256d s, __mmask8 k, void * a);\n`"},{"name":"\u200b","value":"`VEXPANDPD __m256d _mm256_maskz_expandloadu_pd( __mmask8 k, void * a);\n`"},{"name":"\u200b","value":"`VEXPANDPD __m128d _mm_mask_expand_pd( __m128d s, __mmask8 k, __m128d a);\n`"},{"name":"\u200b","value":"`VEXPANDPD __m128d _mm_maskz_expand_pd( __mmask8 k, __m128d a);\n`"},{"name":"\u200b","value":"`VEXPANDPD __m128d _mm_mask_expandloadu_pd( __m128d s, __mmask8 k, void * a);\n`"},{"name":"\u200b","value":"`VEXPANDPD __m128d _mm_maskz_expandloadu_pd( __mmask8 k, void * a);\n`"},{"name":"CPUID Flags","value":"AVX512VL AVX512F"}],"footer":{"text":"Thanks to Felix Cloutier for the online x86 reference"}}