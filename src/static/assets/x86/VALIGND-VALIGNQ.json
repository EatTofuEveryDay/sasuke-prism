{"title":"VALIGND/VALIGNQ â€” Align Doubleword/Quadword Vectors","fields":[{"name":"Instruction Modes","value":"`ib VALIGND xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst, imm8`\n`ib VALIGNQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst, imm8`\n`ib VALIGND ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst, imm8`\n`ib VALIGNQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst, imm8`\n`ib VALIGND zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst, imm8`\n`ib VALIGNQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst, imm8`"},{"name":"Description","value":"Concatenates and shifts right doubleword/quadword elements of the first source operand (the second operand) and the second source operand (the third operand) into a 1024/512/256-bit intermediate vector. The low 512/256/128-bit of the intermediate vector is written to the destination operand (the first operand) using the writemask k1. The destination and first source operands are ZMM/YMM/XMM registers. The second source operand can be a ZMM/YMM/XMM register, a 512/256/128-bit memory location or a 512/256/128-bit vector broadcasted from a 32/64-bit memory location."},{"name":"\u200b","value":"This instruction is writemasked, so only those elements with the corresponding bit set in vector mask register k1 are computed and stored into zmm1. Elements in zmm1 with the corresponding bit clear in k1 retain their previous values (merging-masking) or are set to 0 (zeroing-masking)."},{"name":"C/C++ Intriniscs","value":"`VALIGND __m512i _mm512_alignr_epi32( __m512i a, __m512i b, int cnt);\n`"},{"name":"\u200b","value":"`VALIGND __m512i _mm512_mask_alignr_epi32(__m512i s, __mmask16 k, __m512i a, __m512i b, int cnt);\n`"},{"name":"\u200b","value":"`VALIGND __m512i _mm512_maskz_alignr_epi32( __mmask16 k, __m512i a, __m512i b, int cnt);\n`"},{"name":"\u200b","value":"`VALIGND __m256i _mm256_mask_alignr_epi32(__m256i s, __mmask8 k, __m256i a, __m256i b, int cnt);\n`"},{"name":"\u200b","value":"`VALIGND __m256i _mm256_maskz_alignr_epi32( __mmask8 k, __m256i a, __m256i b, int cnt);\n`"},{"name":"\u200b","value":"`VALIGND __m128i _mm_mask_alignr_epi32(__m128i s, __mmask8 k, __m128i a, __m128i b, int cnt);\n`"},{"name":"\u200b","value":"`VALIGND __m128i _mm_maskz_alignr_epi32( __mmask8 k, __m128i a, __m128i b, int cnt);\n`"},{"name":"\u200b","value":"`VALIGNQ __m512i _mm512_alignr_epi64( __m512i a, __m512i b, int cnt);\n`"},{"name":"\u200b","value":"`VALIGNQ __m512i _mm512_mask_alignr_epi64(__m512i s, __mmask8 k, __m512i a, __m512i b, int cnt);\n`"},{"name":"\u200b","value":"`VALIGNQ __m512i _mm512_maskz_alignr_epi64( __mmask8 k, __m512i a, __m512i b, int cnt);\n`"},{"name":"\u200b","value":"`VALIGNQ __m256i _mm256_mask_alignr_epi64(__m256i s, __mmask8 k, __m256i a, __m256i b, int cnt);\n`"},{"name":"\u200b","value":"`VALIGNQ __m256i _mm256_maskz_alignr_epi64( __mmask8 k, __m256i a, __m256i b, int cnt);\n`"},{"name":"\u200b","value":"`VALIGNQ __m128i _mm_mask_alignr_epi64(__m128i s, __mmask8 k, __m128i a, __m128i b, int cnt);\n`"},{"name":"\u200b","value":"`VALIGNQ __m128i _mm_maskz_alignr_epi64( __mmask8 k, __m128i a, __m128i b, int cnt);\n`"},{"name":"CPUID Flags","value":"AVX512VL AVX512F"}],"footer":{"text":"Thanks to Felix Cloutier for the online x86 reference"}}